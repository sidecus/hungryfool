[{"content":"Docker‚Äôs cache mount (--mount=type=cache) looks simple on the surface, but it hides an important mental model that often trips people up‚Äîespecially when mixing root vs non-root users, different home directories, or multi-stage builds.\nThis post explains how cache mounts actually work, why they don‚Äôt share by default, and how to correctly share them, using uv cache as a concrete example.\nHow Cache Mount Actually Works Consider this Dockerfile instruction:\nRUN --mount=type=cache,target=/root/.cache/uv \\ uv sync When Docker executes this, it creates a named cache volume. The cache is keyed by:\nThe builder instance The target path (/root/.cache/uv) An optional cache ID (if you provide one) Now compare it with:\nRUN --mount=type=cache,target=/home/vscode/.cache/uv \\ uv sync Even if:\nit‚Äôs the same Dockerfile same base image same machine same uv.lock Docker treats this as a completely different cache.\nDifferent target path = different cache volume\nSo these do not share cache:\n/root/.cache/uv ‚ùå /home/vscode/.cache/uv ‚ùå Why Docker Behaves This Way (Important Mental Model) Cache mounts are not filesystem overlays.\nThey are explicit cache volumes, and Docker intentionally isolates them unless you tell it otherwise.\nThe simplified mental model is:\ncache-key = (builder, cache-id OR target-path) If you:\nchange users change home directories change paths ‚Ä¶you‚Äôve implicitly changed the cache key.\nThis design avoids accidental cache corruption, but it means sharing is opt-in, not automatic.\nHow to Force Cache Sharing (The Correct Way) To share cache across users, paths, stages, or images, you must use an explicit cache ID.\nRUN --mount=type=cache,id=uv-cache,target=/root/.cache/uv \\ uv sync Later:\nRUN --mount=type=cache,id=uv-cache,target=/home/vscode/.cache/uv \\ uv sync Now Docker sees:\nSame id=uv-cache Different target paths ‚úÖ Same underlying cache volume This is the intended and supported way to share caches across users (root / non-root), paths, stages, images.\nBest Practice for uv Cache Mounts For uv, the cleanest approach is to standardize the cache directory across images:\nENV UV_CACHE_DIR=/cache/uv RUN --mount=type=cache,id=uv-cache,target=${UV_CACHE_DIR} \\ uv sync This avoids:\nPermission mismatches User home directory confusion Accidental cache fragmentation One Subtle but Critical Detail: Permissions If you share a cache between root and non-root users, permissions matter.\nIf the cache directory isn‚Äôt writable (or at least readable) by both, you‚Äôll see:\npermission denied errors wheels not reused silent cache misses A pragmatic solution during build:\nENV UV_CACHE_DIR=/cache/uv RUN --mount=type=cache,id=uv-cache,target=${UV_CACHE_DIR} \\ chmod -R 0777 /cache/uv || true This ensures the cache remains usable regardless of UID.\nTL;DR Scenario Cache Shared? Different targets, no id ‚ùå No Same target path ‚úÖ Yes Different targets, same id ‚úÖ Yes Different users, same id ‚úÖ Yes Rule of thumb:\nüëâ If you want sharing, always set id explicitly.\nFollow-Up Read: Dev Containers Caveat This solution only applies to build-time caches. You cannot use Docker cache mounts as runtime mounts inside containers including dev containers.\nFor example, this will not work:\n// devcontainer.json \u0026#34;mounts\u0026#34;: [ \u0026#34;type=cache,id=uv-cache,target=/cache/uv\u0026#34; ] Cache mounts:\nexist only during docker build do not persist into running containers behave the same for application containers and dev containers How do we benefit from uv cache in dev containers then?\nYou can make cache mounts work when building the dev container, but it requires referencing a custom Dockerfile in devcontainer.json, which adds devops complexity. Personally I prefer a simpler solution to let all dev containers share one uv cache volume using an explicit volume mount at runtime instead.\n// devcontainer.json \u0026#34;containerEnv\u0026#34;: { \u0026#34;UV_CACHE_DIR\u0026#34;: \u0026#34;/uvcache\u0026#34; }, \u0026#34;mounts\u0026#34;: [ \u0026#34;source=${localEnv:UV_CACHE_DIR},target=/uvcache,type=bind,consistency=cached\u0026#34; ] Though this does not reuse the bulid time cache mount, it ensures all your dev containers reuse the same uv cache volume.\nOne extra cache copy, but simpler, faster, fewer surprises.\n","permalink":"https://www.hungryfool.net/posts/docker-cache-mount---uv-as-an-example/","summary":"\u003cp\u003eDocker‚Äôs \u003ca href=\"https://docs.docker.com/build/cache/optimize/#use-cache-mounts\"\u003ecache mount\u003c/a\u003e (\u003ccode\u003e--mount=type=cache\u003c/code\u003e) looks simple on the surface, but it hides an important mental model that often trips people up‚Äîespecially when mixing \u003cstrong\u003eroot vs non-root users\u003c/strong\u003e, \u003cstrong\u003edifferent home directories\u003c/strong\u003e, or \u003cstrong\u003emulti-stage builds\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThis post explains \u003cstrong\u003ehow cache mounts actually work\u003c/strong\u003e, \u003cstrong\u003ewhy they don‚Äôt share by default\u003c/strong\u003e, and \u003cstrong\u003ehow to correctly share them\u003c/strong\u003e, using \u003ca href=\"https://docs.astral.sh/uv/concepts/cache/#cache-directory\"\u003e\u003ccode\u003euv\u003c/code\u003e cache\u003c/a\u003e as a concrete example.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"how-cache-mount-actually-works\"\u003eHow Cache Mount Actually Works\u003c/h2\u003e\n\u003cp\u003eConsider this Dockerfile instruction:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-dockerfile\" data-lang=\"dockerfile\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e --mount\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etype\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003ecache,target\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e/root/.cache/uv \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    uv sync\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWhen Docker executes this, it creates a \u003cstrong\u003enamed cache volume\u003c/strong\u003e. The cache is keyed by:\u003c/p\u003e","title":"Docker Cache Mount - uv as an Example"},{"content":"Two announcements this week felt like markers of a shift.\nn8n, the open-source automation platform, raised $180 million in Series C funding. And OpenAI introduced its Agent Builder, letting anyone create AI agents inside ChatGPT. Different origins ‚Äî same direction: turning intelligence into action.\nFrom Models to Systems For past few years, AI progress was measured by bigger, smarter models. But real-world problems aren‚Äôt solved by a single prompt. They‚Äôre solved through flows ‚Äî pulling data, judging conditions, handling exceptions, finishing tasks.\nThat‚Äôs not just intelligence; it‚Äôs orchestration. And this is where agents come in ‚Äî systems that reason, act, and adapt.\nn8n‚Äôs Recent Raise n8n has quietly become the bridge between models and work. With this new funding, it‚Äôs betting on AI workflow orchestration: connecting APIs, evaluating results, and enabling feedback loops. That means automation that doesn‚Äôt just execute ‚Äî it learns.\nIt‚Äôs a sign investors now value the plumbing of intelligence as much as the intelligence itself.\nOpenAI‚Äôs Agent Builder While n8n builds from the infrastructure layer up, OpenAI builds from the model layer down. Its Agent Builder and AgentKit turn ChatGPT into a platform for small, task-driven agents ‚Äî connecting reasoning to real actions.\nOpenAI, n8n, and others like ByteDance‚Äôs Coze are converging toward the same goal: usable, reliable, self-improving automation.\nWhy This Matters AI doesn‚Äôt fail because it‚Äôs dumb ‚Äî it fails because it‚Äôs disconnected. We don‚Äôt just need smarter models; we need systems that know when to act, when to stop, and how to learn.\nAgent automation brings:\nContext ‚Äî linking steps across data and APIs Evaluation ‚Äî knowing what works and what fails Governance ‚Äî boundaries, monitoring, and human oversight These layers are what make AI useful in real businesses.\nA Personal Reflection For me, this shift is exciting because it reframes the challenge. It‚Äôs no longer ‚ÄúCan we make models think?‚Äù but ‚ÄúCan we make them do ‚Äî safely, transparently, and meaningfully?‚Äù\nMaybe the next big leap won‚Äôt come from another foundation model. It‚Äôll come from agents that quietly, intelligently, make work flow.\nStay hungry, stay foolish ‚Äî and keep building.\n","permalink":"https://www.hungryfool.net/posts/agent-rising-turn-intelligence-into-action/","summary":"AI workflow automation company n8n\u0026rsquo;s $180M series-c funding and OpenAI\u0026rsquo;s recent announcement of Agent Builder show that industry values the plumbing of intelligence as much as the intelligence itself.","title":"Agents Rising: Turning Intelligence into Action"},{"content":"I stumbled upon a paper this week called ‚ÄúPsychologically Enhanced AI Agents‚Äù, and it got me thinking: what if AI really had personality ‚Äî not just polite tones or emojis, but an inner ‚Äúway of thinking‚Äù?\nThe authors built something called MBTI-in-Thoughts (MiT) ‚Äî basically, a way to give large language models different MBTI types through prompts. No fine-tuning, no extra data, just clever framing. You tell the model it‚Äôs an INFJ or an ENTP, then see if it actually behaves that way. Turns out, it kind of does.\nFeeling types write warmer, more emotional stories. Thinking types stay logical and consistent in planning tasks. Introverts are a bit more reflective, while extroverts are chattier and more flexible in group settings. It‚Äôs not magic ‚Äî the model‚Äôs still the same underneath ‚Äî but the patterns are surprisingly human-like.\nWhat I found most interesting isn‚Äôt the technical side, but the psychological echo. These ‚Äúpersonalities‚Äù affect how the AIs cooperate, argue, or make choices. Even without any ‚Äúreal‚Äù self, they start to feel more relatable, or at least more understandable. It‚Äôs like giving structure to their chaos ‚Äî and maybe to ours too.\nOf course, MBTI isn‚Äôt perfect science. Psychologists have debated its reliability for years. But even if it‚Äôs a rough framework, it‚Äôs a familiar language for thinking about differences ‚Äî human or artificial.\nFor me, this paper isn‚Äôt about proving that AI can ‚Äúfeel.‚Äù It‚Äôs about designing intention: how we choose to make AI think, reason, and respond. Maybe one day, we‚Äôll switch between AI personalities depending on what we need ‚Äî a calm INFJ coach, a bold ENTJ strategist, or a curious INTP brainstormer.\nIt‚Äôs a strange thought, but also kind of beautiful. Maybe personality ‚Äî human or machine ‚Äî is just a lens for how we see the world, and how we choose to care about it.\n","permalink":"https://www.hungryfool.net/posts/agent-with-mbti-personality/","summary":"Researchers found that enhancing AI agents with MBTI personality can enhance the way agents act and make them more suitable for tasks in various scenarios.","title":"Agent With MBTI Personality"},{"content":"Every new experience in the computer world starts with the famous \u0026ldquo;Hello World\u0026rdquo;.\nSo here is the \u0026ldquo;Hello World\u0026rdquo; for my blog.\n","permalink":"https://www.hungryfool.net/posts/helloworld/","summary":"First post using Hugo.","title":"Hello World"}]